{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Data ETL\n",
    "\n",
    "This notebook reads in the .mat simulation data created for the CognitiveGrid project and loads it into BTrDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import uuid\n",
    "import glob\n",
    "import json \n",
    "import btrdb\n",
    "import scipy.io\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from btrdb.utils.timez import ns_delta, to_nanoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "DATA_FILES = glob.glob(\"BESS_*.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract MAT files to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframes(files=DATA_FILES):\n",
    "    \"\"\"\n",
    "    Load tables from .mat file and events CSV and return a\n",
    "    dictionary of pandas DataFrames for the data.\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    \n",
    "    for fpath in files:\n",
    "        key = fpath.rstrip(\".mat\")\n",
    "        dat = scipy.io.loadmat(fpath)\n",
    "        arr = dat[key]\n",
    "        typ = arr.dtype\n",
    "        \n",
    "        # Stupid depth extraction\n",
    "        assert len(arr) == 1\n",
    "        arr = arr[0]\n",
    "        assert len(arr) == 1\n",
    "        arr = arr[0]\n",
    "        assert len(arr) == 12\n",
    "        \n",
    "        cols = []\n",
    "        for idx, col in enumerate(arr):\n",
    "            assert col.shape == (100000, 1)\n",
    "            col = pd.Series(map(np.float64, col), name=typ.names[idx])\n",
    "            cols.append(col)\n",
    "        \n",
    "        dfs[key] = pd.concat(cols, axis=1)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "def save_hdf(data, path):\n",
    "    \"\"\"\n",
    "    Save the dictionary of DataFrames as an HDF5 file.\n",
    "    \"\"\"\n",
    "    # Use append mode, so delete existing file\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    \n",
    "    for key, df in data.items():\n",
    "        df.to_hdf(path, key=key, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL to transform data into HDF5 Data\n",
    "data = load_dataframes(DATA_FILES)\n",
    "save_hdf(data, \"pow_epfl.hdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"2018-08-29T15:30:00.000Z\" # The time of the GitHub commit of the files (rounded)\n",
    "PATH = \"pow_epfl.hdf\"\n",
    "KEYS = [\n",
    "    'BESS_0_to_m500', \n",
    "    'BESS_m500_to_p500', \n",
    "    'BESS_0_to_m200', \n",
    "    'BESS_0_to_p200', \n",
    "    'BESS_idle', \n",
    "    'BESS_0_to_p500',\n",
    "]\n",
    "COLS = ['V1', 'V2', 'V3', 'ia1', 'ia2', 'ia3', 'ib1', 'ib2', 'ib3', 'ic1', 'ic2', 'ic3']\n",
    "\n",
    "\n",
    "def get_dataframe(path=PATH, key=KEYS[0], start=START):\n",
    "    start = to_nanoseconds(start)\n",
    "    times = start + np.array(1e9*np.linspace(0,2,100000), dtype=np.int64)\n",
    "        \n",
    "    df = pd.read_hdf(path, key=key)\n",
    "    df.index = times\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_streams(path=PATH, keys=KEYS, start=START, cols=COLS, interval=2):\n",
    "    dfs = []\n",
    "    start = to_nanoseconds(start)\n",
    "    interval = ns_delta(seconds=interval)\n",
    "    \n",
    "    for idx, key in enumerate(keys):\n",
    "        begin = start + (idx*interval)\n",
    "        dfs.append(get_dataframe(path, key, begin))\n",
    "    \n",
    "    for col in cols:\n",
    "        s = pd.concat([df[col] for df in dfs], axis=0)\n",
    "        s.name=col\n",
    "        yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>ia1</th>\n",
       "      <th>ia2</th>\n",
       "      <th>ia3</th>\n",
       "      <th>ib1</th>\n",
       "      <th>ib2</th>\n",
       "      <th>ib3</th>\n",
       "      <th>ic1</th>\n",
       "      <th>ic2</th>\n",
       "      <th>ic3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535556600000000000</th>\n",
       "      <td>3.33659</td>\n",
       "      <td>1.43620</td>\n",
       "      <td>-4.77706</td>\n",
       "      <td>0.293283</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>-0.267342</td>\n",
       "      <td>-0.622578</td>\n",
       "      <td>0.200201</td>\n",
       "      <td>0.333262</td>\n",
       "      <td>-0.205084</td>\n",
       "      <td>0.409253</td>\n",
       "      <td>-0.496841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535556600000020000</th>\n",
       "      <td>3.31034</td>\n",
       "      <td>1.46428</td>\n",
       "      <td>-4.78225</td>\n",
       "      <td>0.293893</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>-0.277413</td>\n",
       "      <td>-0.617695</td>\n",
       "      <td>0.203864</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>-0.211493</td>\n",
       "      <td>0.426649</td>\n",
       "      <td>-0.509354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535556600000040000</th>\n",
       "      <td>3.29112</td>\n",
       "      <td>1.49541</td>\n",
       "      <td>-4.78866</td>\n",
       "      <td>0.302438</td>\n",
       "      <td>0.082095</td>\n",
       "      <td>-0.281991</td>\n",
       "      <td>-0.619221</td>\n",
       "      <td>0.201117</td>\n",
       "      <td>0.326853</td>\n",
       "      <td>-0.225837</td>\n",
       "      <td>0.439772</td>\n",
       "      <td>-0.509354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535556600000060000</th>\n",
       "      <td>3.26487</td>\n",
       "      <td>1.52928</td>\n",
       "      <td>-4.79415</td>\n",
       "      <td>0.303354</td>\n",
       "      <td>0.097354</td>\n",
       "      <td>-0.292978</td>\n",
       "      <td>-0.619221</td>\n",
       "      <td>0.204779</td>\n",
       "      <td>0.333567</td>\n",
       "      <td>-0.225837</td>\n",
       "      <td>0.437025</td>\n",
       "      <td>-0.501724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535556600000080000</th>\n",
       "      <td>3.23923</td>\n",
       "      <td>1.55889</td>\n",
       "      <td>-4.80087</td>\n",
       "      <td>0.309763</td>\n",
       "      <td>0.099490</td>\n",
       "      <td>-0.300607</td>\n",
       "      <td>-0.612812</td>\n",
       "      <td>0.206915</td>\n",
       "      <td>0.327158</td>\n",
       "      <td>-0.234077</td>\n",
       "      <td>0.427564</td>\n",
       "      <td>-0.481277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          V1       V2       V3       ia1       ia2       ia3  \\\n",
       "1535556600000000000  3.33659  1.43620 -4.77706  0.293283  0.083316 -0.267342   \n",
       "1535556600000020000  3.31034  1.46428 -4.78225  0.293893  0.081179 -0.277413   \n",
       "1535556600000040000  3.29112  1.49541 -4.78866  0.302438  0.082095 -0.281991   \n",
       "1535556600000060000  3.26487  1.52928 -4.79415  0.303354  0.097354 -0.292978   \n",
       "1535556600000080000  3.23923  1.55889 -4.80087  0.309763  0.099490 -0.300607   \n",
       "\n",
       "                          ib1       ib2       ib3       ic1       ic2  \\\n",
       "1535556600000000000 -0.622578  0.200201  0.333262 -0.205084  0.409253   \n",
       "1535556600000020000 -0.617695  0.203864  0.331126 -0.211493  0.426649   \n",
       "1535556600000040000 -0.619221  0.201117  0.326853 -0.225837  0.439772   \n",
       "1535556600000060000 -0.619221  0.204779  0.333567 -0.225837  0.437025   \n",
       "1535556600000080000 -0.612812  0.206915  0.327158 -0.234077  0.427564   \n",
       "\n",
       "                          ic3  \n",
       "1535556600000000000 -0.496841  \n",
       "1535556600000020000 -0.509354  \n",
       "1535556600000040000 -0.509354  \n",
       "1535556600000060000 -0.501724  \n",
       "1535556600000080000 -0.481277  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = get_streams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
